{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e45ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4f248c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "        system_message = SystemMessage(content=f\"Summary of conversation earlier: {summary}\")\n",
    "        messages = [system_message] + state[\"messages\"]\n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    if summary:\n",
    "        summary_message = HumanMessage(content=(\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        ))\n",
    "    else:\n",
    "        summary_message = HumanMessage(content=\"Create a summary of the conversation above:\")\n",
    "\n",
    "    messages = state[\"messages\"] + [summary_message]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "\n",
    "def should_continue(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d995036",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "conn = sqlite3.connect(\"state_db/example.db\", check_same_thread=False)\n",
    "memory = SqliteSaver(conn)\n",
    "graph = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "addf246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi again, Lance! It's great to hear from you. Since you like the 49ers, would you like to dive into a specific topic about the team? Or is there something else you'd like to chat about? Let me know!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance! üòä Did I get it right?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's awesome, Lance! The 49ers are such a legendary team with a rich history. Do you have a favorite player, past or present? Or maybe a favorite game or moment? Let‚Äôs talk Niners! üèà\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "627c79d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='425c043e-d52a-4ec1-8b26-8db8579012b8'), AIMessage(content=\"Hi again, Lance! It's great to hear from you. Since you like the 49ers, would you like to dive into a specific topic about the team? Or is there something else you'd like to chat about? Let me know!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 337, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BrMESykvBSLJ8QfRWYa87lug7CP0F', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--555ac8b8-326a-48ae-9cd6-ea7fbc20d906-0', usage_metadata={'input_tokens': 337, 'output_tokens': 49, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='4ed407ae-816b-4fd0-b783-d6cf9cf437b9'), AIMessage(content='Your name is Lance! üòä Did I get it right?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 241, 'total_tokens': 254, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ab9114d383', 'id': 'chatcmpl-BrMEWUVbOOqiNaTIHQLEjcja8zxfe', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--b05e51e9-95bb-4fd8-b485-0abc9293ed99-0', usage_metadata={'input_tokens': 241, 'output_tokens': 13, 'total_tokens': 254, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='i like the 49ers!', additional_kwargs={}, response_metadata={}, id='7a4031a4-3879-4772-aaf1-8e97b77b5d9d'), AIMessage(content=\"That's awesome, Lance! The 49ers are such a legendary team with a rich history. Do you have a favorite player, past or present? Or maybe a favorite game or moment? Let‚Äôs talk Niners! üèà\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 268, 'total_tokens': 316, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_ee1d74bde0', 'id': 'chatcmpl-BrMEXFBsJigPVgJXCuGKYPbd0AM1w', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--4a8d3d8c-8321-4c24-9de2-5a600bb2dd31-0', usage_metadata={'input_tokens': 268, 'output_tokens': 48, 'total_tokens': 316, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'summary': 'Here\\'s an updated summary of the conversation:\\n\\nLance introduced himself multiple times during the conversation, consistently stating, \"Hi! I\\'m Lance.\" He also expressed his fondness for the San Francisco 49ers football team. The AI assistant acknowledged Lance\\'s name each time and enthusiastically engaged with his interest in the 49ers, offering to discuss various aspects of the team, such as their history, current roster, memorable games, rivalries, or future prospects. Despite the AI\\'s attempts to steer the conversation toward specific topics about the 49ers, Lance continued to reintroduce himself without directly responding to the AI\\'s questions or prompts. The conversation remained light and repetitive, with Lance\\'s focus on reintroducing himself and the AI\\'s focus on encouraging a deeper discussion about the 49ers.'}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f05cae9-e731-684e-801b-ea0eba683eaa'}}, metadata={'source': 'loop', 'step': 27, 'parents': {}, 'thread_id': '1'}, created_at='2025-07-09T10:22:30.089310+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f05cae9-deb4-6768-801a-f723d47b5380'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "graph_state = graph.get_state(config)\n",
    "graph_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df95ac1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
